# 蒙特卡洛方法

蒙特卡洛模拟是一个广义的术语，指的是使用随机数和统计抽样来解决问题的方法，而不是精确建模。从这种抽样的性质来看，结果会有一些不确定性，但统计学上的 "大数定理 "会确保不确定性随着样本数量的增加而下降。

统计抽样的一个重要工具是随机数发生器。参见教程32，了解随机数生成。

## 激励

让我们从一个简单的例子开始：测量一个面积，例如，$\pi$是刻在边长为2的正方形中的一个圆的面积。如果你在正方形中随机选取一个点，它落入圆内的几率是𝜋/4，所以你可以通过选取许多随机点$(x,y)$来估计这个比例，看看它们的长度$\sqrt{x^2+y^2}$小于1的比例是多少。

你甚至可以把它作为一个物理实验来做：假设你的后院有一个不规则形状的池塘，而院子本身是已知尺寸的长方形。如果你现在向院子里扔卵石，使它们在任何给定的地方都有同样的可能性，那么落在池塘里的卵石和落在外面的卵石的比例就等于面积的比例。

抛开幻想，从数学角度讲，我们需要将落在你所测量的形状内或外的想法正式化。因此，让$\Omega\in [0，1]^2$作为形状，让一个函数$f(\tilde{x})$来描述$\Omega$的边界，也就是
$$
\left\{\begin{array}{ll}
f(\bar{x})<0 & x \notin \Omega \\
f(\bar{x})>0 & x \in \Omega
\end{array}\right.
$$
现在取随机点$\tilde{x}_0,\tilde{x}_1,\tilde{x}_2在[0,1]^2$，然后我们可以通过计算$f(\bar{x}_i)$为正或负的频率来估计Ω的面积。

我们可以把这个想法扩展到积分。一个函数在一个区间$(a, b)$上的平均值定义为
$$
\langle f\rangle=\frac{1}{b-a} \int_{a}^{b} f(x) d x
$$
另一方面，我们也可以估计平均数为
$$
\langle f\rangle \approx \frac{1}{N} \sum_{i=1}^{n} f\left(x_{i}\right)
$$
如果点𝑥的分布合理，并且函数𝑓不是太疯狂的话。这使我们得出
$$
\int_{a}^{b} f(x) d x \approx(b-a) \frac{1}{N} \sum_{i=1}^{n} f\left(x_{i}\right)
$$
我们不打算讨论的统计理论告诉我们，积分中的不确定性$\sigma_I$与下列因素有关。标准偏差$\sigma_f$的关系为
$$
\sigma_{I} \sim \frac{1}{\sqrt{N}} \sigma_{f}
$$
为正态分布。

### 吸引人的地方是什么？

到目前为止，蒙特卡洛积分看起来与经典的黎曼和积分没有什么区别。当我们上升到更高的维度时，差别就出现了。在这种情况下，对于经典积分，我们需要在每个维度上有$N$个点，导致在$N$个维度上有$d$个点。另一方面，在蒙特卡洛方法中，点是从$d$维空间中随机抽取的，而且点的数量少得多。

在计算方面，蒙特卡洛方法很有吸引力，因为所有的函数评估都可以并行进行。

这方面的统计规律如下：如果对一个标准差为$\sigma$的量进行$N$独立观测，那么平均值的标准差为$\sigma / \sqrt{N}$。这意味着更多的服务将导致更多的准确性；使蒙特卡洛方法有趣的是，这种准确性的提高与原始问题的维度无关。

蒙特卡洛技术当然是模拟具有统计性质的现象的自然候选者，如放射性衰变或布朗运动。蒙特卡洛模拟具有吸引力的其他问题则不属于科学计算的范畴。例如，用于股票期权定价的Black-Scholes模型[15]就使用了蒙特卡洛模拟。

一些你以前见过的问题，如解线性方程组，可以用蒙特卡洛技术来解决。然而，这并不是一个典型的应用。下面我们将讨论两个应用，在这些应用中，精确的方法需要花费太多的时间来计算，而统计抽样可以很快给出一个相当准确的答案。

## 示例

### 伊辛模型的蒙特卡洛模拟

伊辛模型（介绍见[33]）最初是为了模拟铁磁性而提出的。磁性是原子排列其 "自旋 "方向的结果：假设自旋只能是 "向上 "或 "向下"，那么如果有更多的原子自旋向上，而不是向下，那么这种材料就具有磁性，反之亦然。这些原子被称为 "晶格 "结构中的原子。

现在想象一下，加热一种材料，使原子松动。如果在材料上施加一个外部场，原子将开始与场对齐，如果场被移除，磁性又消失了。然而，在某个临界温度以下，材料将保留其磁性。我们将使用蒙特卡洛模拟来寻找保留的稳定构型。

假设晶格$\Lambda$有$N$个原子，我们把原子的配置表示为$\sigma=(\sigma_1，...，\sigma_N)$，其中每个$\sigma_i=\pm1$。 晶格的能量模型为
$$
H=H(\sigma)=-J \sum_{i} \sigma_{i}-E \sum_{i j} \sigma_{i} \sigma_{j}
$$
第一个项模拟单个自旋$\sigma_i$与强度为$J$的外部场的相互作用。第二项是对近邻对的求和，模拟原子对的排列：如果原子具有相同的自旋，则乘积$\sigma_i\sigma_j$为正，如果相反则为负。

在统计力学中，一个配置的概率是
$$
P(\sigma)=\exp (-H(\sigma)) / Z
$$
其中 "分区函数 "$Z$定义为
$$
Z=\sum_{\sigma} \exp (H(\sigma))
$$
其中，总和在所有$2^N$配置上运行。

如果一个配置的能量在小的扰动下没有减少，那么它就是稳定的。为了探索这一点，我们在晶格上进行迭代，探索改变原子的自旋是否会降低能量。我们引入了一个偶然因素来防止人为的解决方案。(这就是Metropolis算法[155]）。

```c
for fixed number of iterations do for each atom 𝑖 do
calculate the change Δ𝐸 from changing the sign of 𝜎𝑖
if Δ𝐸 < or exp(−Δ𝐸) greater than some random number then
accept the change
```

如果我们注意到与稀疏矩阵-向量乘积结构的相似性，这种算法可以被并行化。在该算法中，我们也是通过结合几个近邻的输入来计算一个局部数量。这意味着我们可以对晶格进行分区，在每个处理器收集到一个幽灵区域后计算局部更新。

让每个处理器在晶格中的局部点上迭代，相当于晶格的一个特定的全局排序；为了使并行计算等同于顺序计算，我们还需要一个并行随机发生器（第32.3节）。

